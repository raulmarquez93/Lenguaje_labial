{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Extraer  dataset\n"
      ],
      "metadata": {
        "id": "aOz1J28K_ijd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C86rOf5hnUh",
        "outputId": "b6f8e052-b1cd-4edd-90c3-ae372c0a8c90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening zip file: inferencia_np.zip\n",
            "Found 12 members in the zip file.\n",
            "Successfully extracted: inferencia_np/\n",
            "Successfully extracted: inferencia_np/inferencia.npy\n",
            "Successfully extracted: inferencia_np/inferencia_10_0009.npy\n",
            "Successfully extracted: inferencia_np/inferencia_1_0000.npy\n",
            "Successfully extracted: inferencia_np/inferencia_2_0001.npy\n",
            "Successfully extracted: inferencia_np/inferencia_3_0002.npy\n",
            "Successfully extracted: inferencia_np/inferencia_4_0003.npy\n",
            "Successfully extracted: inferencia_np/inferencia_5_0004.npy\n",
            "Successfully extracted: inferencia_np/inferencia_6_0005.npy\n",
            "Successfully extracted: inferencia_np/inferencia_7_0006.npy\n",
            "Successfully extracted: inferencia_np/inferencia_8_0007.npy\n",
            "Successfully extracted: inferencia_np/inferencia_9_0008.npy\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = 'inferencia_np.zip'\n",
        "extract_dir = '/content/arrays_np'\n",
        "\n",
        "# Ensure the extraction directory exists\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        print(f\"Opening zip file: {zip_file_path}\")\n",
        "        file_list = zip_ref.namelist()\n",
        "        print(f\"Found {len(file_list)} members in the zip file.\")\n",
        "\n",
        "        for member in file_list:\n",
        "            try:\n",
        "                # Extract each member individually\n",
        "                zip_ref.extract(member, extract_dir)\n",
        "                print(f\"Successfully extracted: {member}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error extracting {member}: {e}\")\n",
        "                # You can add more specific error handling here if needed\n",
        "                # For example, check if it's a permission error or a data error\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: Zip file not found at {zip_file_path}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"‚ùå Error: The file {zip_file_path} is not a valid zip file or is corrupted.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inferencia\n"
      ],
      "metadata": {
        "id": "ggPkgGqB_q0c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNXzuygOi_lA",
        "outputId": "c0524eae-cea9-42c9-e4c9-62c6ba7ae85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç 11 archivos encontrados para inferencia.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step\n",
            "üìÅ inferencia_9_0008.npy ‚Üí Predicho: 1 | Real: 9 | ‚ùå Incorrecto\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "üìÅ inferencia_5_0004.npy ‚Üí Predicho: 1 | Real: 5 | ‚ùå Incorrecto\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "üìÅ inferencia_4_0003.npy ‚Üí Predicho: 4 | Real: 4 | ‚úÖ Correcto\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "‚ùå Error con inferencia.npy: list index out of range\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "üìÅ inferencia_8_0007.npy ‚Üí Predicho: 4 | Real: 8 | ‚ùå Incorrecto\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "üìÅ inferencia_10_0009.npy ‚Üí Predicho: 10 | Real: 10 | ‚úÖ Correcto\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "üìÅ inferencia_2_0001.npy ‚Üí Predicho: 4 | Real: 2 | ‚ùå Incorrecto\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "üìÅ inferencia_7_0006.npy ‚Üí Predicho: 3 | Real: 7 | ‚ùå Incorrecto\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "üìÅ inferencia_1_0000.npy ‚Üí Predicho: 10 | Real: 1 | ‚ùå Incorrecto\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "üìÅ inferencia_3_0002.npy ‚Üí Predicho: 3 | Real: 3 | ‚úÖ Correcto\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "üìÅ inferencia_6_0005.npy ‚Üí Predicho: 3 | Real: 6 | ‚ùå Incorrecto\n",
            "\n",
            "üéØ Tasa de acierto: 30.00% (3/10)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# üìç Ruta al modelo y al directorio de prueba\n",
        "modelo_path = '/content/modelo.h5'\n",
        "test_dir = '/content/arrays_np/inferencia_np'\n",
        "\n",
        "# üì¶ Cargar modelo entrenado\n",
        "model = tf.keras.models.load_model(modelo_path)\n",
        "\n",
        "# üîé Buscar archivos que comiencen por \"grabacion\" y terminen en .npy\n",
        "test_files = [f for f in os.listdir(test_dir)]\n",
        "\n",
        "print(f\"üîç {len(test_files)} archivos encontrados para inferencia.\")\n",
        "\n",
        "# üìä Contadores\n",
        "aciertos = 0\n",
        "total = 0\n",
        "\n",
        "# üß™ Procesar cada archivo\n",
        "for file in test_files:\n",
        "    path = os.path.join(test_dir, file)\n",
        "    try:\n",
        "        X = np.load(path)\n",
        "\n",
        "        if X.shape != (30, 128, 128, 1):\n",
        "            print(f\"‚ö†Ô∏è {file} tiene forma incorrecta: {X.shape}\")\n",
        "            continue\n",
        "\n",
        "        # üßº Preprocesamiento\n",
        "        X = X / 255.0\n",
        "        X = np.expand_dims(X, axis=0)\n",
        "\n",
        "        # ü§ñ Predicci√≥n\n",
        "        pred = model.predict(X)\n",
        "        pred_class = np.argmax(pred) + 1\n",
        "\n",
        "        # üéØ Clase real desde el nombre del archivo (3er elemento)\n",
        "        real_class = int(file.split(\"_\")[1])\n",
        "\n",
        "        # ‚úîÔ∏è Comparar y contar\n",
        "        correcto = pred_class == real_class\n",
        "        if correcto:\n",
        "            aciertos += 1\n",
        "        total += 1\n",
        "\n",
        "        print(f\"üìÅ {file} ‚Üí Predicho: {pred_class} | Real: {real_class} | {'‚úÖ Correcto' if correcto else '‚ùå Incorrecto'}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error con {file}: {e}\")\n",
        "\n",
        "# üìà Mostrar tasa de acierto\n",
        "if total > 0:\n",
        "    tasa_acierto = aciertos / total * 100\n",
        "    print(f\"\\nüéØ Tasa de acierto: {tasa_acierto:.2f}% ({aciertos}/{total})\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No se procesaron archivos correctamente.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento\n"
      ],
      "metadata": {
        "id": "QkPUEhyU_uPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "# üöÄ Configuraci√≥n\n",
        "data_dir = '/content/arrays_np/arrays7_np'\n",
        "batch_size = 1\n",
        "epochs = 30\n",
        "input_shape = (30, 128, 128, 1)\n",
        "num_classes = 10\n",
        "\n",
        "# üöÄ Definir Generador de Datos\n",
        "class NPYDataGenerator(Sequence):\n",
        "    def __init__(self, file_paths, labels, batch_size=1, num_classes=10, shuffle=True):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_paths = self.file_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_labels = self.labels[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        X = []\n",
        "        for path in batch_paths:\n",
        "            array = np.load(path)\n",
        "            if array.shape != (30, 128, 128, 1):\n",
        "                raise ValueError(f\"Archivo con forma incorrecta: {path} ‚Üí {array.shape}\")\n",
        "            X.append(array / 255.0)\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = tf.keras.utils.to_categorical(np.array(batch_labels), num_classes=self.num_classes)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            temp = list(zip(self.file_paths, self.labels))\n",
        "            np.random.shuffle(temp)\n",
        "            self.file_paths, self.labels = zip(*temp)\n",
        "\n",
        "# üöÄ Cargar rutas y etiquetas\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "for file in os.listdir(data_dir):\n",
        "    if file.endswith(\".npy\"):\n",
        "        path = os.path.join(data_dir, file)\n",
        "        file_paths.append(path)\n",
        "        label = int(file.split(\"_\")[1])\n",
        "        labels.append(label -1)\n",
        "\n",
        "file_paths = np.array(file_paths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"Total archivos:\", len(file_paths))\n",
        "\n",
        "# ‚úÖ Crear carpeta de resultados\n",
        "os.makedirs(\"/content/Resultados\", exist_ok=True)\n",
        "\n",
        "# üöÄ Dividir datos en entrenamiento y validaci√≥n\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    file_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# üöÄ Generadores\n",
        "train_gen = NPYDataGenerator(train_paths, train_labels, batch_size=batch_size, num_classes=num_classes)\n",
        "val_gen = NPYDataGenerator(val_paths, val_labels, batch_size=batch_size, num_classes=num_classes, shuffle=False)\n",
        "\n",
        "# üöÄ Modelo\n",
        "input_layer = Input(shape=input_shape)\n",
        "x = TimeDistributed(Conv2D(32, (3,3), activation='relu', padding='same'))(input_layer)\n",
        "x = TimeDistributed(MaxPooling2D((2,2)))(x)\n",
        "x = TimeDistributed(Conv2D(64, (3,3), activation='relu', padding='same'))(x)\n",
        "x = TimeDistributed(MaxPooling2D((2,2)))(x)\n",
        "x = TimeDistributed(Flatten())(x)\n",
        "x = LSTM(128)(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# üöÄ Callbacks\n",
        "checkpoint_path = '/content/Resultados/modelo.h5'\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "# üöÄ Entrenamiento\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# üé® Gr√°fica de Accuracy y Loss\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axs[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
        "axs[0].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "axs[0].set_title('Accuracy')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(history.history['loss'], label='Train Loss')\n",
        "axs[1].plot(history.history['val_loss'], label='Val Loss')\n",
        "axs[1].set_title('Loss')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.savefig('/content/Resultados/grafica_entrenamiento.png')\n",
        "plt.close()\n",
        "\n",
        "# üéØ Matriz de Confusi√≥n\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for i in range(len(val_gen)):\n",
        "    X_batch, y_batch = val_gen[i]\n",
        "    preds = model.predict(X_batch)\n",
        "    preds_classes = np.argmax(preds, axis=1)\n",
        "    true_classes = np.argmax(y_batch, axis=1)\n",
        "\n",
        "    y_true.extend(true_classes)\n",
        "    y_pred.extend(preds_classes)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title('Matriz de Confusi√≥n')\n",
        "plt.savefig('/content/Resultados/matriz_confusion.png')\n",
        "plt.close()\n",
        "\n",
        "report = classification_report(y_true, y_pred, output_dict=True)\n",
        "with open('/content/Resultados/clasificacion.json', 'w') as f:\n",
        "    json.dump(report, f, indent=4)\n",
        "\n",
        "print(\"\\n‚úÖ ¬°Entrenamiento completado! Modelo, gr√°ficas, matriz de confusi√≥n y reporte guardados.\")\n"
      ],
      "metadata": {
        "id": "C5k2_5fi_hBU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V6E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}